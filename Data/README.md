# ğŸ“Š Data â€” Supply Chain Visibility & Predictive Analysis

This folder contains all datasets used throughout the project.  
They are **synthetic, anonymized, and created for academic demonstration only** â€” replicating real-world supply chain structures such as orders, shipments, and suppliers.

---

## ğŸ“ Folder Structure

Data/
â”£ ğŸ“ raw/ # Original input CSVs (source layer)

â”£ ğŸ“ clean/ # Processed & joined data for ML + Power BI

â”£ ğŸ“ ml-outputs/ # Model predictions (forecast + delays)

â”£ ğŸ“„ README.md # You're here


---

## ğŸ—ƒï¸ Dataset Overview

| Dataset | Folder | Description | Used In |
|----------|---------|--------------|----------|
| **orders.csv** | `/raw/` | All customer orders with product, region, and date details | Power BI & ML |
| **shipments.csv** | `/raw/` | Shipment information incl. status, route, and delivery dates | Power BI & ML |
| **suppliers.csv** | `/raw/` | Supplier performance data (lead time, rating) | Power BI (Suppliers Page) |
| **fact_orders.csv** | `/clean/` | Merged and cleaned orders dataset | Power BI Overview |
| **fact_shipments.csv** | `/clean/` | Shipment-level analytics dataset | Power BI Operations |
| **forecast_fact.csv** | `/ml-outputs/` | ML model output: predicted vs actual demand | Power BI Forecast |
| **shipment_delay_pred.csv** | `/ml-outputs/` | ML output: predicted delay days per shipment | Power BI Risk Insights |

---

## âš™ï¸ Data Flow Summary

Raw (GitHub CSVs)
â†“
Cleaned & merged (Colab notebooks)
â†“
ML outputs (forecast + delay)
â†“
Power BI report (pbix visuals)


Each stage simulates **Azure Blob zones**:
- `/raw/` â†’ corresponds to `Blob/raw/`
- `/clean/` â†’ corresponds to `Blob/clean/`
- `/ml-outputs/` â†’ corresponds to `Blob/ml-outputs/`

---

## ğŸ§  Data Dictionary Reference
For detailed column names, data types, and example values,  
see ğŸ‘‰ [`Documentation/Data-Dictionary.md`](../Documentation/Data-Dictionary.md)

---

## ğŸª¶ Notes
- All data are sample or generated for testing, **not confidential**.  
- Versioning is handled through Git commits.  
- Large data files may be uploaded via **Git LFS** if they exceed 100 MB.

---


